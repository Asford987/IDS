{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing_functions_file_path = 'pre_processing_functions.pkl'\n",
    "model_file_path = 'extreme_gradient_boosting.pkl'\n",
    "dataset_file_path = './Datasets/CSE-CIC-IDS2018/raw/original/02-14-2018.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label_mapping': array(['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS',\n",
      "       'DDOS attack-HOIC', 'DDOS attack-LOIC-UDP',\n",
      "       'DoS attacks-GoldenEye', 'DoS attacks-Hulk',\n",
      "       'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris',\n",
      "       'FTP-BruteForce', 'Infilteration', 'Label', 'SQL Injection',\n",
      "       'SSH-Bruteforce'], dtype=object), 'inputer': <bound method SimpleImputer.transform of SimpleImputer(strategy='median')>, 'scaler': <bound method MinMaxScaler.transform of MinMaxScaler()>, 'transformer': <bound method QuantileTransformer.transform of QuantileTransformer()>, 'pca': <bound method _BasePCA.transform of PCA(n_components=30)>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Projetos\\pfc-ime\\venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.5.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\Projetos\\pfc-ime\\venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\Projetos\\pfc-ime\\venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator QuantileTransformer from version 1.5.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\Projetos\\pfc-ime\\venv\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.5.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the actual path to your .pkl file\n",
    "with open(pre_processing_functions_file_path, 'rb') as file:\n",
    "    functions = pickle.load(file)\n",
    "\n",
    "# Now 'my_dict' is a dictionary\n",
    "print(functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = './Datasets/CSE-CIC-IDS2018/raw/original/02-14-2018.csv'\n",
    "dataset = pd.read_csv(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Deleta a coluna Timestamp\n",
    "df = df.drop(columns=['Timestamp', 'Label'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate throught each dataframe in the dictionary\n",
    "for key in df.keys():\n",
    "    for col in df.columns:\n",
    "        #Check if the datatype of the column is object\n",
    "        if df[col].dtype == 'object' and col != 'Label':\n",
    "            # Change all values to numeric, and to NaN if it is a strig\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inputed = functions['inputer'](df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = functions['transformer'](X_inputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = functions['scaler'](X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = functions['pca'](X_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_treated = X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\Projetos\\pfc-ime\\venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:32:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the actual path to your .pkl file\n",
    "with open(model_file_path, 'rb') as file:\n",
    "    model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(logs_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
