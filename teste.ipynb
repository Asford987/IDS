{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class ExpertModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_units, dropout_rate):\n",
    "        super(ExpertModel, self).__init__()\n",
    "        layers = []\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = units\n",
    "        layers.append(nn.Linear(input_dim, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class GateModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts, hidden_units, dropout_rate):\n",
    "        super(GateModel, self).__init__()\n",
    "        layers = []\n",
    "        for units in hidden_units:\n",
    "            layers.append(nn.Linear(input_dim, units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = units\n",
    "        layers.append(nn.Linear(input_dim, num_experts))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.softmax(self.model(x), dim=1)\n",
    "\n",
    "\n",
    "class MixtureOfExperts(pl.LightningModule):\n",
    "    def __init__(self, input_dim, output_dim, num_experts, expert_hidden_units, gate_hidden_units, num_active_experts, dropout_rate, learning_rate=1e-3):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.experts = nn.ModuleList([ExpertModel(input_dim, output_dim, expert_hidden_units, dropout_rate) for _ in range(num_experts)])\n",
    "        self.gate = GateModel(input_dim, num_experts, gate_hidden_units, dropout_rate)\n",
    "        self.num_active_experts = num_active_experts\n",
    "        self.expert_usage_count = torch.zeros(num_experts, dtype=torch.float32)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=1)\n",
    "        gate_output = self.gate(x)\n",
    "\n",
    "        expert_usage_count_adjusted = self.expert_usage_count + 1e-10\n",
    "        importance_scores = gate_output / expert_usage_count_adjusted\n",
    "\n",
    "        top_n_expert_indices = torch.argsort(importance_scores, dim=1, descending=True)[:, :self.num_active_experts]\n",
    "        selected_expert_indices = top_n_expert_indices.view(-1)\n",
    "\n",
    "        self.expert_usage_count += torch.bincount(selected_expert_indices, minlength=len(self.experts)).float()\n",
    "\n",
    "        mask = torch.sum(F.one_hot(top_n_expert_indices, num_classes=len(self.experts)), dim=1)\n",
    "        masked_gate_output = gate_output * mask\n",
    "        normalized_gate_output = masked_gate_output / (torch.sum(masked_gate_output, dim=1, keepdim=True) + 1e-7)\n",
    "\n",
    "        masked_expert_outputs = torch.stack([expert_outputs[:, i] * normalized_gate_output[:, i].unsqueeze(1)\n",
    "                                              for i in range(len(self.experts))], dim=1)\n",
    "        final_output = torch.sum(masked_expert_outputs, dim=1)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        f2_score = fbeta_score(y.cpu().numpy(), preds.cpu().numpy(), beta=2, average='macro')\n",
    "        self.log('val_f2', f2_score, prog_bar=True, sync_dist=True)\n",
    "        return {'val_f2': f2_score}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.1, patience=5, verbose=True\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_f2',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        self.expert_usage_count = self.expert_usage_count.to(self.device)\n",
    "\n",
    "class ExpertUsageLogger(pl.Callback):\n",
    "    def __init__(self, moe_model):\n",
    "        super(ExpertUsageLogger, self).__init__()\n",
    "        self.moe_model = moe_model\n",
    "        self.expert_usage_history = []\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        usage_count = self.moe_model.expert_usage_count.clone().cpu().numpy()\n",
    "        self.expert_usage_history.append(usage_count)\n",
    "\n",
    "    def plot_expert_usage(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        usage_history = torch.tensor(self.expert_usage_history)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i in range(usage_history.shape[1]):\n",
    "            plt.plot(usage_history[:, i], label=f'Expert {i}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Expert Usage Count')\n",
    "        plt.title('Expert Usage Over Epochs')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'CIC_IoMT_2024_WiFi_MQTT_train.parquet'\n",
    "test_data_path = 'CIC_IoMT_2024_WiFi_MQTT_test.parquet'\n",
    "usage_ratio=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Header_Length       822146\n",
       "Protocol Type         1441\n",
       "Duration              2684\n",
       "Rate               4174510\n",
       "Srate              4174510\n",
       "Drate                    1\n",
       "fin_flag_number        229\n",
       "syn_flag_number        525\n",
       "rst_flag_number        501\n",
       "psh_flag_number        428\n",
       "ack_flag_number        619\n",
       "ece_flag_number          8\n",
       "cwr_flag_number          6\n",
       "ack_count              563\n",
       "syn_count              986\n",
       "fin_count             2605\n",
       "rst_count            11333\n",
       "HTTP                    33\n",
       "HTTPS                  257\n",
       "DNS                     62\n",
       "Telnet                   6\n",
       "SMTP                     7\n",
       "SSH                     14\n",
       "IRC                      7\n",
       "TCP                    253\n",
       "UDP                    282\n",
       "DHCP                    33\n",
       "ARP                     72\n",
       "ICMP                   227\n",
       "IGMP                    13\n",
       "IPv                     72\n",
       "LLC                     72\n",
       "Tot sum               6502\n",
       "Min                   5117\n",
       "Max                   5287\n",
       "AVG                   5291\n",
       "Std                  13274\n",
       "Tot size              5275\n",
       "IAT                  68531\n",
       "Number                  86\n",
       "Magnitue              2637\n",
       "Radius               12993\n",
       "Covariance          717859\n",
       "Variance               772\n",
       "Weight                  92\n",
       "label                   51\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7160831 entries, 0 to 7160830\n",
      "Data columns (total 46 columns):\n",
      " #   Column           Dtype   \n",
      "---  ------           -----   \n",
      " 0   Header_Length    float32 \n",
      " 1   Protocol Type    float16 \n",
      " 2   Duration         float16 \n",
      " 3   Rate             float32 \n",
      " 4   Srate            float32 \n",
      " 5   Drate            int8    \n",
      " 6   fin_flag_number  float16 \n",
      " 7   syn_flag_number  float16 \n",
      " 8   rst_flag_number  float16 \n",
      " 9   psh_flag_number  float16 \n",
      " 10  ack_flag_number  float16 \n",
      " 11  ece_flag_number  float16 \n",
      " 12  cwr_flag_number  float16 \n",
      " 13  ack_count        float16 \n",
      " 14  syn_count        float16 \n",
      " 15  fin_count        float16 \n",
      " 16  rst_count        float16 \n",
      " 17  HTTP             float16 \n",
      " 18  HTTPS            float16 \n",
      " 19  DNS              float16 \n",
      " 20  Telnet           float16 \n",
      " 21  SMTP             float16 \n",
      " 22  SSH              float16 \n",
      " 23  IRC              float16 \n",
      " 24  TCP              float16 \n",
      " 25  UDP              float16 \n",
      " 26  DHCP             float16 \n",
      " 27  ARP              float16 \n",
      " 28  ICMP             float16 \n",
      " 29  IGMP             float16 \n",
      " 30  IPv              float16 \n",
      " 31  LLC              float16 \n",
      " 32  Tot sum          float16 \n",
      " 33  Min              float16 \n",
      " 34  Max              float16 \n",
      " 35  AVG              float16 \n",
      " 36  Std              float16 \n",
      " 37  Tot size         float16 \n",
      " 38  IAT              float32 \n",
      " 39  Number           float16 \n",
      " 40  Magnitue         float16 \n",
      " 41  Radius           float16 \n",
      " 42  Covariance       float32 \n",
      " 43  Variance         float16 \n",
      " 44  Weight           float16 \n",
      " 45  label            category\n",
      "dtypes: category(1), float16(39), float32(5), int8(1)\n",
      "memory usage: 682.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet(train_data_path)\n",
    "df_test = pd.read_parquet(test_data_path)\n",
    "\n",
    "# Combine train and test data\n",
    "df_combined = pd.concat([df_train, df_test])\n",
    "\n",
    "display(df_train.nunique())\n",
    "df_train.info()\n",
    "# Perform stratified sampling\n",
    "df_sampled, _ = train_test_split(df_combined, train_size=usage_ratio, stratify=df_combined['label'], random_state=42)\n",
    "\n",
    "# Split back into train and test based on the original indices\n",
    "df_train: pd.DataFrame = df_sampled[df_sampled.index.isin(df_train.index)]\n",
    "df_test: pd.DataFrame = df_sampled[df_sampled.index.isin(df_test.index)]\n",
    "numeric_columns = df_train.select_dtypes(include=[np.number]).columns\n",
    "df_train[numeric_columns] = df_train[numeric_columns].astype(np.float32)\n",
    "df_test[numeric_columns] = df_test[numeric_columns].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1755002 entries, 5278661 to 3488986\n",
      "Data columns (total 46 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   Header_Length    float32\n",
      " 1   Protocol Type    float32\n",
      " 2   Duration         float32\n",
      " 3   Rate             float32\n",
      " 4   Srate            float32\n",
      " 5   Drate            float32\n",
      " 6   fin_flag_number  float32\n",
      " 7   syn_flag_number  float32\n",
      " 8   rst_flag_number  float32\n",
      " 9   psh_flag_number  float32\n",
      " 10  ack_flag_number  float32\n",
      " 11  ece_flag_number  float32\n",
      " 12  cwr_flag_number  float32\n",
      " 13  ack_count        float32\n",
      " 14  syn_count        float32\n",
      " 15  fin_count        float32\n",
      " 16  rst_count        float32\n",
      " 17  HTTP             float32\n",
      " 18  HTTPS            float32\n",
      " 19  DNS              float32\n",
      " 20  Telnet           float32\n",
      " 21  SMTP             float32\n",
      " 22  SSH              float32\n",
      " 23  IRC              float32\n",
      " 24  TCP              float32\n",
      " 25  UDP              float32\n",
      " 26  DHCP             float32\n",
      " 27  ARP              float32\n",
      " 28  ICMP             float32\n",
      " 29  IGMP             float32\n",
      " 30  IPv              float32\n",
      " 31  LLC              float32\n",
      " 32  Tot sum          float32\n",
      " 33  Min              float32\n",
      " 34  Max              float32\n",
      " 35  AVG              float32\n",
      " 36  Std              float32\n",
      " 37  Tot size         float32\n",
      " 38  IAT              float32\n",
      " 39  Number           float32\n",
      " 40  Magnitue         float32\n",
      " 41  Radius           float32\n",
      " 42  Covariance       float32\n",
      " 43  Variance         float32\n",
      " 44  Weight           float32\n",
      " 45  label            object \n",
      "dtypes: float32(45), object(1)\n",
      "memory usage: 328.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Header_Length       282568\n",
       "Protocol Type          965\n",
       "Duration              2115\n",
       "Rate               1131368\n",
       "Srate              1131368\n",
       "Drate                    1\n",
       "fin_flag_number        125\n",
       "syn_flag_number        228\n",
       "rst_flag_number        219\n",
       "psh_flag_number        188\n",
       "ack_flag_number        250\n",
       "ece_flag_number          5\n",
       "cwr_flag_number          4\n",
       "ack_count              331\n",
       "syn_count              578\n",
       "fin_count             1835\n",
       "rst_count            10928\n",
       "HTTP                    25\n",
       "HTTPS                  142\n",
       "DNS                     37\n",
       "Telnet                   3\n",
       "SMTP                     4\n",
       "SSH                     10\n",
       "IRC                      4\n",
       "TCP                    143\n",
       "UDP                    152\n",
       "DHCP                    17\n",
       "ARP                     64\n",
       "ICMP                   135\n",
       "IGMP                    12\n",
       "IPv                     64\n",
       "LLC                     64\n",
       "Tot sum               6057\n",
       "Min                   4304\n",
       "Max                   5274\n",
       "AVG                   5240\n",
       "Std                  12737\n",
       "Tot size              5151\n",
       "IAT                  23957\n",
       "Number                  82\n",
       "Magnitue              2621\n",
       "Radius               12480\n",
       "Covariance          195748\n",
       "Variance               289\n",
       "Weight                  88\n",
       "label                   72\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01000214, 0.60009766, 0.19995117, 0.02000427,\n",
       "       0.39990234, 0.09997559, 0.41992188, 0.2199707 , 0.30004883,\n",
       "       0.36010742, 0.5600586 , 0.23999023, 0.4399414 , 0.13000488,\n",
       "       0.02999878, 0.35009766], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['DHCP'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [col for col in df_train.columns if col not in ['label', 'Drate']]\n",
    "\n",
    "target_train = df_train['label']\n",
    "df_train = df_train.drop(columns=['label', 'Drate'])\n",
    "target_test = df_test['label']\n",
    "df_test = df_test.drop(columns=['label', 'Drate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of missing values: {df_train.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1755002.0</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "      <td>1.755002e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.988337e+04</td>\n",
       "      <td>8.046584e+00</td>\n",
       "      <td>6.463663e+01</td>\n",
       "      <td>1.573294e+04</td>\n",
       "      <td>1.573294e+04</td>\n",
       "      <td>5.101282e-03</td>\n",
       "      <td>1.571194e-01</td>\n",
       "      <td>3.962176e-02</td>\n",
       "      <td>2.219948e-02</td>\n",
       "      <td>9.567751e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.053767e+01</td>\n",
       "      <td>6.038682e+00</td>\n",
       "      <td>6.053738e+01</td>\n",
       "      <td>84678376.0</td>\n",
       "      <td>9.498865e+00</td>\n",
       "      <td>1.043581e+01</td>\n",
       "      <td>8.529323e+00</td>\n",
       "      <td>2.367965e+03</td>\n",
       "      <td>9.065043e-02</td>\n",
       "      <td>1.414742e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.814616e+05</td>\n",
       "      <td>6.304724e+00</td>\n",
       "      <td>7.837749e+00</td>\n",
       "      <td>4.000080e+04</td>\n",
       "      <td>4.000080e+04</td>\n",
       "      <td>3.395753e-02</td>\n",
       "      <td>3.367704e-01</td>\n",
       "      <td>1.395269e-01</td>\n",
       "      <td>9.655753e-02</td>\n",
       "      <td>2.522283e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.783871e+01</td>\n",
       "      <td>3.802954e+01</td>\n",
       "      <td>8.758988e+01</td>\n",
       "      <td>17817836.0</td>\n",
       "      <td>8.414046e-01</td>\n",
       "      <td>3.150808e+00</td>\n",
       "      <td>5.376392e+01</td>\n",
       "      <td>1.980274e+04</td>\n",
       "      <td>2.328664e-01</td>\n",
       "      <td>2.166214e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.164062e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.310000e+00</td>\n",
       "      <td>1.049805e+00</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>6.428900e+00</td>\n",
       "      <td>6.428900e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.209375e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.225000e+01</td>\n",
       "      <td>84679176.0</td>\n",
       "      <td>9.500000e+00</td>\n",
       "      <td>9.171875e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.415000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>1.331385e+02</td>\n",
       "      <td>1.331385e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>84696416.0</td>\n",
       "      <td>9.500000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.415000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.940038e+04</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>1.976398e+04</td>\n",
       "      <td>1.976398e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>84696904.0</td>\n",
       "      <td>9.500000e+00</td>\n",
       "      <td>1.039062e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.415000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.892476e+06</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.097152e+06</td>\n",
       "      <td>2.097152e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>7.205000e+02</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>169470848.0</td>\n",
       "      <td>1.350000e+01</td>\n",
       "      <td>5.503125e+01</td>\n",
       "      <td>1.019500e+03</td>\n",
       "      <td>5.197575e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.446250e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Header_Length  Protocol Type      Duration          Rate         Srate  \\\n",
       "count   1.755002e+06   1.755002e+06  1.755002e+06  1.755002e+06  1.755002e+06   \n",
       "mean    2.988337e+04   8.046584e+00  6.463663e+01  1.573294e+04  1.573294e+04   \n",
       "std     2.814616e+05   6.304724e+00  7.837749e+00  4.000080e+04  4.000080e+04   \n",
       "min     0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%     2.310000e+00   1.049805e+00  6.400000e+01  6.428900e+00  6.428900e+00   \n",
       "50%     1.080000e+02   6.000000e+00  6.400000e+01  1.331385e+02  1.331385e+02   \n",
       "75%     1.940038e+04   1.700000e+01  6.400000e+01  1.976398e+04  1.976398e+04   \n",
       "max     9.892476e+06   1.700000e+01  2.550000e+02  2.097152e+06  2.097152e+06   \n",
       "\n",
       "       fin_flag_number  syn_flag_number  rst_flag_number  psh_flag_number  \\\n",
       "count     1.755002e+06     1.755002e+06     1.755002e+06     1.755002e+06   \n",
       "mean      5.101282e-03     1.571194e-01     3.962176e-02     2.219948e-02   \n",
       "std       3.395753e-02     3.367704e-01     1.395269e-01     9.655753e-02   \n",
       "min       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "50%       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "75%       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "max       1.000000e+00     1.000000e+00     1.000000e+00     1.000000e+00   \n",
       "\n",
       "       ack_flag_number  ...           AVG           Std      Tot size  \\\n",
       "count     1.755002e+06  ...  1.755002e+06  1.755002e+06  1.755002e+06   \n",
       "mean      9.567751e-02  ...  6.053767e+01  6.038682e+00  6.053738e+01   \n",
       "std       2.522283e-01  ...  8.783871e+01  3.802954e+01  8.758988e+01   \n",
       "min       0.000000e+00  ...  4.200000e+01  0.000000e+00  4.200000e+01   \n",
       "25%       0.000000e+00  ...  4.209375e+01  0.000000e+00  4.225000e+01   \n",
       "50%       0.000000e+00  ...  5.000000e+01  0.000000e+00  5.000000e+01   \n",
       "75%       0.000000e+00  ...  5.400000e+01  0.000000e+00  5.400000e+01   \n",
       "max       1.000000e+00  ...  1.514000e+03  7.205000e+02  1.514000e+03   \n",
       "\n",
       "               IAT        Number      Magnitue        Radius    Covariance  \\\n",
       "count    1755002.0  1.755002e+06  1.755002e+06  1.755002e+06  1.755002e+06   \n",
       "mean    84678376.0  9.498865e+00  1.043581e+01  8.529323e+00  2.367965e+03   \n",
       "std     17817836.0  8.414046e-01  3.150808e+00  5.376392e+01  1.980274e+04   \n",
       "min            0.0  1.000000e+00  9.164062e+00  0.000000e+00  0.000000e+00   \n",
       "25%     84679176.0  9.500000e+00  9.171875e+00  0.000000e+00  0.000000e+00   \n",
       "50%     84696416.0  9.500000e+00  1.000000e+01  0.000000e+00  0.000000e+00   \n",
       "75%     84696904.0  9.500000e+00  1.039062e+01  0.000000e+00  0.000000e+00   \n",
       "max    169470848.0  1.350000e+01  5.503125e+01  1.019500e+03  5.197575e+05   \n",
       "\n",
       "           Variance        Weight  \n",
       "count  1.755002e+06  1.755002e+06  \n",
       "mean   9.065043e-02  1.414742e+02  \n",
       "std    2.328664e-01  2.166214e+01  \n",
       "min    0.000000e+00  1.000000e+00  \n",
       "25%    0.000000e+00  1.415000e+02  \n",
       "50%    0.000000e+00  1.415000e+02  \n",
       "75%    0.000000e+00  1.415000e+02  \n",
       "max    1.000000e+00  2.446250e+02  \n",
       "\n",
       "[8 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "target_train_encoded = encoder.fit_transform(target_train.values.reshape(-1, 1))\n",
    "target_test_encoded = encoder.transform(target_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1755002, 1), (645668, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_encoded.shape, target_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185096 out of 1755002 samples were filtered out as outliers.\n",
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "z_scores = np.abs(stats.zscore(df_train[numerical_columns].astype(np.float64)))\n",
    "\n",
    "outlier_mask = np.any(z_scores > 4, axis=1)\n",
    "\n",
    "# Filter out rows with outliers\n",
    "df_train = df_train[~outlier_mask]\n",
    "target_train_encoded = target_train_encoded[~outlier_mask]\n",
    "\n",
    "print(f\"{outlier_mask.sum()} out of {len(outlier_mask)} samples were filtered out as outliers.\")\n",
    "print(f\"Number of missing values: {df_train.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6192364</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>165.400284</td>\n",
       "      <td>165.400284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>84697032.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.164062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117584</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>68.792351</td>\n",
       "      <td>68.792351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0000</td>\n",
       "      <td>84696112.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.390625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621097</th>\n",
       "      <td>100.120003</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.615251</td>\n",
       "      <td>5.615251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219971</td>\n",
       "      <td>...</td>\n",
       "      <td>54.96875</td>\n",
       "      <td>0.580566</td>\n",
       "      <td>54.8750</td>\n",
       "      <td>84674744.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.484375</td>\n",
       "      <td>0.808105</td>\n",
       "      <td>0.917855</td>\n",
       "      <td>0.379883</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595882</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.294065</td>\n",
       "      <td>25.294065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>84697072.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.164062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978704</th>\n",
       "      <td>8825.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>142711.765625</td>\n",
       "      <td>142711.765625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>84675256.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292793</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>31.164721</td>\n",
       "      <td>31.164721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>84697048.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.164062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920754</th>\n",
       "      <td>21680.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13038.194336</td>\n",
       "      <td>13038.194336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>84696736.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846606</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>234.213593</td>\n",
       "      <td>234.213593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>84697024.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.164062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415335</th>\n",
       "      <td>453.559998</td>\n",
       "      <td>1.160156</td>\n",
       "      <td>64.0</td>\n",
       "      <td>154.241364</td>\n",
       "      <td>154.241364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.56250</td>\n",
       "      <td>1.955078</td>\n",
       "      <td>42.5625</td>\n",
       "      <td>84679320.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.226562</td>\n",
       "      <td>2.769531</td>\n",
       "      <td>29.984301</td>\n",
       "      <td>0.130005</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711708</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24672.376953</td>\n",
       "      <td>24672.376953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>84697064.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.164062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156073</th>\n",
       "      <td>1390.140015</td>\n",
       "      <td>1.160156</td>\n",
       "      <td>64.0</td>\n",
       "      <td>175.178085</td>\n",
       "      <td>175.178085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>42.18750</td>\n",
       "      <td>0.803223</td>\n",
       "      <td>43.8125</td>\n",
       "      <td>84697024.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.187500</td>\n",
       "      <td>1.149414</td>\n",
       "      <td>33.032246</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966243</th>\n",
       "      <td>268.200012</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1201.781006</td>\n",
       "      <td>1201.781006</td>\n",
       "      <td>0.140015</td>\n",
       "      <td>0.379883</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.150024</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>...</td>\n",
       "      <td>70.56250</td>\n",
       "      <td>3.921875</td>\n",
       "      <td>70.8125</td>\n",
       "      <td>84667024.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.882812</td>\n",
       "      <td>5.550781</td>\n",
       "      <td>19.465574</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127639</th>\n",
       "      <td>33561.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>57201.484375</td>\n",
       "      <td>57201.484375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>84696864.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033476</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.799332</td>\n",
       "      <td>0.799332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.0000</td>\n",
       "      <td>84674568.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.390625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226330</th>\n",
       "      <td>17145.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17074.560547</td>\n",
       "      <td>17074.560547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>84696648.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Header_Length  Protocol Type  Duration           Rate          Srate  \\\n",
       "6192364       0.000000       1.000000      64.0     165.400284     165.400284   \n",
       "7117584      54.000000       6.000000      64.0      68.792351      68.792351   \n",
       "621097      100.120003       6.000000      64.0       5.615251       5.615251   \n",
       "595882        0.000000       1.000000      64.0      25.294065      25.294065   \n",
       "5978704    8825.000000      17.000000      64.0  142711.765625  142711.765625   \n",
       "6292793       0.000000       1.000000      64.0      31.164721      31.164721   \n",
       "6920754   21680.500000      17.000000      64.0   13038.194336   13038.194336   \n",
       "846606        0.000000       1.000000      64.0     234.213593     234.213593   \n",
       "6415335     453.559998       1.160156      64.0     154.241364     154.241364   \n",
       "1711708       0.000000       1.000000      64.0   24672.376953   24672.376953   \n",
       "6156073    1390.140015       1.160156      64.0     175.178085     175.178085   \n",
       "1966243     268.200012       6.000000      64.0    1201.781006    1201.781006   \n",
       "1127639   33561.000000      17.000000      64.0   57201.484375   57201.484375   \n",
       "4033476      54.000000       6.000000      64.0       0.799332       0.799332   \n",
       "226330    17145.000000      17.000000      64.0   17074.560547   17074.560547   \n",
       "\n",
       "         fin_flag_number  syn_flag_number  rst_flag_number  psh_flag_number  \\\n",
       "6192364         0.000000         0.000000         0.000000         0.000000   \n",
       "7117584         0.000000         0.000000         0.000000         0.000000   \n",
       "621097          0.000000         1.000000         0.000000         0.000000   \n",
       "595882          0.000000         0.000000         0.000000         0.000000   \n",
       "5978704         0.000000         0.000000         0.000000         0.000000   \n",
       "6292793         0.000000         0.000000         0.000000         0.000000   \n",
       "6920754         0.000000         0.000000         0.000000         0.000000   \n",
       "846606          0.000000         0.000000         0.000000         0.000000   \n",
       "6415335         0.000000         0.000000         0.000000         0.000000   \n",
       "1711708         0.000000         0.000000         0.000000         0.000000   \n",
       "6156073         0.000000         0.000000         0.000000         0.000000   \n",
       "1966243         0.140015         0.379883         0.010002         0.150024   \n",
       "1127639         0.000000         0.000000         0.000000         0.000000   \n",
       "4033476         0.000000         1.000000         0.000000         0.000000   \n",
       "226330          0.000000         0.000000         0.000000         0.000000   \n",
       "\n",
       "         ack_flag_number  ...       AVG       Std  Tot size         IAT  \\\n",
       "6192364         0.000000  ...  42.00000  0.000000   42.0000  84697032.0   \n",
       "7117584         0.000000  ...  54.00000  0.000000   54.0000  84696112.0   \n",
       "621097          0.219971  ...  54.96875  0.580566   54.8750  84674744.0   \n",
       "595882          0.000000  ...  42.00000  0.000000   42.0000  84697072.0   \n",
       "5978704         0.000000  ...  50.00000  0.000000   50.0000  84675256.0   \n",
       "6292793         0.000000  ...  42.00000  0.000000   42.0000  84697048.0   \n",
       "6920754         0.000000  ...  50.00000  0.000000   50.0000  84696736.0   \n",
       "846606          0.000000  ...  42.00000  0.000000   42.0000  84697024.0   \n",
       "6415335         0.000000  ...  42.56250  1.955078   42.5625  84679320.0   \n",
       "1711708         0.000000  ...  42.00000  0.000000   42.0000  84697064.0   \n",
       "6156073         0.000000  ...  42.18750  0.803223   43.8125  84697024.0   \n",
       "1966243         0.850098  ...  70.56250  3.921875   70.8125  84667024.0   \n",
       "1127639         0.000000  ...  50.00000  0.000000   50.0000  84696864.0   \n",
       "4033476         0.000000  ...  54.00000  0.000000   54.0000  84674568.0   \n",
       "226330          0.000000  ...  50.00000  0.000000   50.0000  84696648.0   \n",
       "\n",
       "         Number   Magnitue    Radius  Covariance  Variance  Weight  \n",
       "6192364     9.5   9.164062  0.000000    0.000000  0.000000   141.5  \n",
       "7117584     9.5  10.390625  0.000000    0.000000  0.000000   141.5  \n",
       "621097      9.5  10.484375  0.808105    0.917855  0.379883   141.5  \n",
       "595882      9.5   9.164062  0.000000    0.000000  0.000000   141.5  \n",
       "5978704     9.5  10.000000  0.000000    0.000000  0.000000   141.5  \n",
       "6292793     9.5   9.164062  0.000000    0.000000  0.000000   141.5  \n",
       "6920754     9.5  10.000000  0.000000    0.000000  0.000000   141.5  \n",
       "846606      9.5   9.164062  0.000000    0.000000  0.000000   141.5  \n",
       "6415335     9.5   9.226562  2.769531   29.984301  0.130005   141.5  \n",
       "1711708     9.5   9.164062  0.000000    0.000000  0.000000   141.5  \n",
       "6156073     9.5   9.187500  1.149414   33.032246  0.020004   141.5  \n",
       "1966243     9.5  11.882812  5.550781   19.465574  0.830078   141.5  \n",
       "1127639     9.5  10.000000  0.000000    0.000000  0.000000   141.5  \n",
       "4033476     9.5  10.390625  0.000000    0.000000  0.000000   141.5  \n",
       "226330      9.5  10.000000  0.000000    0.000000  0.000000   141.5  \n",
       "\n",
       "[15 rows x 44 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Header_Length      8.671483e+03\n",
       "Protocol Type      8.133665e+00\n",
       "Duration           6.429772e+01\n",
       "Rate               1.382555e+04\n",
       "Srate              1.382555e+04\n",
       "fin_flag_number    2.179058e-04\n",
       "syn_flag_number    1.580998e-01\n",
       "rst_flag_number    2.131322e-02\n",
       "psh_flag_number    1.313877e-03\n",
       "ack_flag_number    3.916546e-02\n",
       "ece_flag_number    0.000000e+00\n",
       "cwr_flag_number    0.000000e+00\n",
       "ack_count          1.003523e-03\n",
       "syn_count          2.447479e-01\n",
       "fin_count          2.861828e-02\n",
       "rst_count          6.779028e-01\n",
       "HTTP               8.658214e-06\n",
       "HTTPS              8.020909e-04\n",
       "DNS                2.159189e-05\n",
       "Telnet             0.000000e+00\n",
       "SMTP               0.000000e+00\n",
       "SSH                2.421044e-07\n",
       "IRC                0.000000e+00\n",
       "TCP                3.660790e-01\n",
       "UDP                3.314583e-01\n",
       "DHCP               0.000000e+00\n",
       "ARP                4.128990e-05\n",
       "ICMP               3.024321e-01\n",
       "IGMP               0.000000e+00\n",
       "IPv                9.999593e-01\n",
       "LLC                9.999593e-01\n",
       "Tot sum            5.256331e+02\n",
       "Min                4.940793e+01\n",
       "Max                5.243468e+01\n",
       "AVG                5.005311e+01\n",
       "Std                1.005190e+00\n",
       "Tot size           5.007597e+01\n",
       "IAT                8.469190e+07\n",
       "Number             9.499704e+00\n",
       "Magnitue           9.951477e+00\n",
       "Radius             1.417852e+00\n",
       "Covariance         3.207044e+02\n",
       "Variance           3.419412e-02\n",
       "Weight             1.414920e+02\n",
       "dtype: float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Header_Length       14451.265625\n",
       "Protocol Type           6.540149\n",
       "Duration                2.056136\n",
       "Rate                25310.832031\n",
       "Srate               25310.832031\n",
       "fin_flag_number         0.004668\n",
       "syn_flag_number         0.344913\n",
       "rst_flag_number         0.084044\n",
       "psh_flag_number         0.016479\n",
       "ack_flag_number         0.145640\n",
       "ece_flag_number         0.000000\n",
       "cwr_flag_number         0.000000\n",
       "ack_count               0.022014\n",
       "syn_count               0.546714\n",
       "fin_count               0.109391\n",
       "rst_count              11.508127\n",
       "HTTP                    0.000392\n",
       "HTTPS                   0.008465\n",
       "DNS                     0.000537\n",
       "Telnet                  0.000000\n",
       "SMTP                    0.000000\n",
       "SSH                     0.000049\n",
       "IRC                     0.000000\n",
       "TCP                     0.480650\n",
       "UDP                     0.468974\n",
       "DHCP                    0.000000\n",
       "ARP                     0.000879\n",
       "ICMP                    0.457853\n",
       "IGMP                    0.000000\n",
       "IPv                     0.000871\n",
       "LLC                     0.000871\n",
       "Tot sum               118.633339\n",
       "Min                     7.436850\n",
       "Max                    23.801250\n",
       "AVG                    11.423596\n",
       "Std                     7.452578\n",
       "Tot size               11.207402\n",
       "IAT                601276.437500\n",
       "Number                  0.015403\n",
       "Magnitue                0.678651\n",
       "Radius                 10.521799\n",
       "Covariance           3770.656494\n",
       "Variance                0.100514\n",
       "Weight                  0.390315\n",
       "dtype: float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = df_train.mean()\n",
    "std = df_train.std()\n",
    "display(mean)\n",
    "display(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n",
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "mean = mean + 1e-5\n",
    "std = std + 1e-5\n",
    "df_train = ((df_train - mean) / std).dropna(axis=1)\n",
    "df_test = ((df_test - mean) / std).dropna(axis=1)\n",
    "\n",
    "print(f\"Number of missing values: {df_train.isna().sum().sum()}\")\n",
    "print(f\"Number of missing values: {df_test.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(df_train, rowvar=False)\n",
    "upper_triangle_indices = np.triu_indices_from(corr_matrix, k=1)\n",
    "correlated_pairs = [(i, j) for i, j in zip(*upper_triangle_indices) if np.abs(corr_matrix[i, j]) >= 0.8]\n",
    "cols_train, cols_test = df_train.columns, df_test.columns\n",
    "correlated_features = set(j for _, j in correlated_pairs)\n",
    "df_train = np.delete(df_train, list(correlated_features), axis=1)\n",
    "df_test = np.delete(df_test, list(correlated_features), axis=1)\n",
    "df_train = pd.DataFrame(df_train, columns=cols_train.drop(cols_train[list(correlated_features)]))\n",
    "df_test = pd.DataFrame(df_test, columns=cols_test.drop(cols_test[list(correlated_features)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate',\n",
       "       'fin_flag_number', 'syn_flag_number', 'rst_flag_number',\n",
       "       'psh_flag_number', 'ack_flag_number', 'ece_flag_number',\n",
       "       'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'rst_count',\n",
       "       'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP',\n",
       "       'DHCP', 'ARP', 'ICMP', 'IGMP', 'IPv', 'LLC', 'Tot sum', 'Min', 'Max',\n",
       "       'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius',\n",
       "       'Covariance', 'Variance', 'Weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>ece_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>IRC</th>\n",
       "      <th>TCP</th>\n",
       "      <th>DHCP</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ICMP</th>\n",
       "      <th>IGMP</th>\n",
       "      <th>Tot sum</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.504455</td>\n",
       "      <td>1.355674</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>-0.032098</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>-0.660552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.005337</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.592524</td>\n",
       "      <td>-0.326242</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>-0.545966</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>1.541884</td>\n",
       "      <td>3.435111</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>2.272168</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.318834</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>-0.660552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.487779</td>\n",
       "      <td>-0.028553</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.041834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850342</td>\n",
       "      <td>1.355674</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>0.249141</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>-0.660552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.005337</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.986055</td>\n",
       "      <td>1.355674</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>-0.095234</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>-0.660552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.005337</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.947427</td>\n",
       "      <td>1.135878</td>\n",
       "      <td>8.214285</td>\n",
       "      <td>0.517582</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>-0.463928</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.218041</td>\n",
       "      <td>0.007956</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>2.246288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569901</th>\n",
       "      <td>-0.592577</td>\n",
       "      <td>-0.326242</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>-0.546201</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.318834</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>-0.660552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.348695</td>\n",
       "      <td>-0.034793</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569902</th>\n",
       "      <td>-0.600050</td>\n",
       "      <td>-1.090750</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>-0.546073</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>1.523509</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.713401</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569903</th>\n",
       "      <td>2.093589</td>\n",
       "      <td>1.355674</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>0.136104</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>-0.660552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.005337</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569904</th>\n",
       "      <td>-0.600050</td>\n",
       "      <td>-1.090750</td>\n",
       "      <td>0.797497</td>\n",
       "      <td>-0.546073</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>1.523509</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.713401</td>\n",
       "      <td>0.008435</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569905</th>\n",
       "      <td>-0.600050</td>\n",
       "      <td>-1.090750</td>\n",
       "      <td>-0.144800</td>\n",
       "      <td>0.685828</td>\n",
       "      <td>-0.048715</td>\n",
       "      <td>-0.458391</td>\n",
       "      <td>-0.253684</td>\n",
       "      <td>-0.080287</td>\n",
       "      <td>-0.268969</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.761638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>1.523509</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.713401</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1569906 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Header_Length  Protocol Type  Duration      Rate  fin_flag_number  \\\n",
       "0             0.504455       1.355674 -0.144800 -0.032098        -0.048715   \n",
       "1            -0.592524      -0.326242 -0.144800 -0.545966        -0.048715   \n",
       "2             0.850342       1.355674 -0.144800  0.249141        -0.048715   \n",
       "3             1.986055       1.355674 -0.144800 -0.095234        -0.048715   \n",
       "4             0.947427       1.135878  8.214285  0.517582        -0.048715   \n",
       "...                ...            ...       ...       ...              ...   \n",
       "1569901      -0.592577      -0.326242 -0.144800 -0.546201        -0.048715   \n",
       "1569902      -0.600050      -1.090750 -0.144800 -0.546073        -0.048715   \n",
       "1569903       2.093589       1.355674 -0.144800  0.136104        -0.048715   \n",
       "1569904      -0.600050      -1.090750  0.797497 -0.546073        -0.048715   \n",
       "1569905      -0.600050      -1.090750 -0.144800  0.685828        -0.048715   \n",
       "\n",
       "         syn_flag_number  rst_flag_number  psh_flag_number  ack_flag_number  \\\n",
       "0              -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "1               1.541884         3.435111        -0.080287         2.272168   \n",
       "2              -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "3              -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "4              -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "...                  ...              ...              ...              ...   \n",
       "1569901        -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "1569902        -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "1569903        -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "1569904        -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "1569905        -0.458391        -0.253684        -0.080287        -0.268969   \n",
       "\n",
       "         ece_flag_number  ...  IRC       TCP  DHCP     ARP      ICMP  IGMP  \\\n",
       "0                   -1.0  ... -1.0 -0.761638  -1.0 -0.0577 -0.660552  -1.0   \n",
       "1                   -1.0  ... -1.0  1.318834  -1.0 -0.0577 -0.660552  -1.0   \n",
       "2                   -1.0  ... -1.0 -0.761638  -1.0 -0.0577 -0.660552  -1.0   \n",
       "3                   -1.0  ... -1.0 -0.761638  -1.0 -0.0577 -0.660552  -1.0   \n",
       "4                   -1.0  ... -1.0 -0.761638  -1.0 -0.0577 -0.463928  -1.0   \n",
       "...                  ...  ...  ...       ...   ...     ...       ...   ...   \n",
       "1569901             -1.0  ... -1.0  1.318834  -1.0 -0.0577 -0.660552  -1.0   \n",
       "1569902             -1.0  ... -1.0 -0.761638  -1.0 -0.0577  1.523509  -1.0   \n",
       "1569903             -1.0  ... -1.0 -0.761638  -1.0 -0.0577 -0.660552  -1.0   \n",
       "1569904             -1.0  ... -1.0 -0.761638  -1.0 -0.0577  1.523509  -1.0   \n",
       "1569905             -1.0  ... -1.0 -0.761638  -1.0 -0.0577  1.523509  -1.0   \n",
       "\n",
       "          Tot sum       IAT    Number  Variance  \n",
       "0       -0.005337  0.008236  0.018562 -0.340259  \n",
       "1        0.487779 -0.028553  0.018562 -0.041834  \n",
       "2       -0.005337  0.008249  0.018562 -0.340259  \n",
       "3       -0.005337  0.008276  0.018562 -0.340259  \n",
       "4        0.218041  0.007956  0.018562  2.246288  \n",
       "...           ...       ...       ...       ...  \n",
       "1569901  0.348695 -0.034793  0.018562 -0.340259  \n",
       "1569902 -0.713401  0.015115  0.018562 -0.340259  \n",
       "1569903 -0.005337  0.007903  0.018562 -0.340259  \n",
       "1569904 -0.713401  0.008435  0.018562 -0.340259  \n",
       "1569905 -0.713401  0.008475  0.018562 -0.340259  \n",
       "\n",
       "[1569906 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.723982</td>\n",
       "      <td>1.405642</td>\n",
       "      <td>-0.509183</td>\n",
       "      <td>-0.043489</td>\n",
       "      <td>-0.453891</td>\n",
       "      <td>0.017190</td>\n",
       "      <td>-0.045733</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>-0.470635</td>\n",
       "      <td>-0.216196</td>\n",
       "      <td>-0.012250</td>\n",
       "      <td>-0.084373</td>\n",
       "      <td>-0.001162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.298144</td>\n",
       "      <td>-1.425085</td>\n",
       "      <td>-1.520087</td>\n",
       "      <td>-0.024649</td>\n",
       "      <td>-0.111459</td>\n",
       "      <td>0.825453</td>\n",
       "      <td>-0.316069</td>\n",
       "      <td>-0.604433</td>\n",
       "      <td>-0.368913</td>\n",
       "      <td>-1.495695</td>\n",
       "      <td>-0.013148</td>\n",
       "      <td>-0.637633</td>\n",
       "      <td>-0.093273</td>\n",
       "      <td>0.901276</td>\n",
       "      <td>0.023981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.785003</td>\n",
       "      <td>1.657681</td>\n",
       "      <td>-0.506929</td>\n",
       "      <td>-0.050599</td>\n",
       "      <td>-0.518908</td>\n",
       "      <td>0.079913</td>\n",
       "      <td>-0.053267</td>\n",
       "      <td>-0.029689</td>\n",
       "      <td>-0.000764</td>\n",
       "      <td>-0.039560</td>\n",
       "      <td>-0.289287</td>\n",
       "      <td>-0.179887</td>\n",
       "      <td>-0.011793</td>\n",
       "      <td>-0.104393</td>\n",
       "      <td>-0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.802038</td>\n",
       "      <td>2.211745</td>\n",
       "      <td>-0.546086</td>\n",
       "      <td>-0.053113</td>\n",
       "      <td>-0.505308</td>\n",
       "      <td>0.063077</td>\n",
       "      <td>-0.056795</td>\n",
       "      <td>-0.051315</td>\n",
       "      <td>-0.048846</td>\n",
       "      <td>-0.215653</td>\n",
       "      <td>-0.828292</td>\n",
       "      <td>-0.296404</td>\n",
       "      <td>-0.022592</td>\n",
       "      <td>-0.271130</td>\n",
       "      <td>-0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.544230</td>\n",
       "      <td>2.852851</td>\n",
       "      <td>1.881443</td>\n",
       "      <td>0.427168</td>\n",
       "      <td>2.744118</td>\n",
       "      <td>5.206410</td>\n",
       "      <td>-0.559283</td>\n",
       "      <td>0.089575</td>\n",
       "      <td>0.541004</td>\n",
       "      <td>1.320186</td>\n",
       "      <td>-1.332039</td>\n",
       "      <td>4.079731</td>\n",
       "      <td>0.281829</td>\n",
       "      <td>1.283006</td>\n",
       "      <td>-0.026053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569901</th>\n",
       "      <td>0.343384</td>\n",
       "      <td>-0.512552</td>\n",
       "      <td>-0.687967</td>\n",
       "      <td>0.027071</td>\n",
       "      <td>0.303698</td>\n",
       "      <td>-0.851152</td>\n",
       "      <td>0.029134</td>\n",
       "      <td>0.315244</td>\n",
       "      <td>0.179364</td>\n",
       "      <td>0.798662</td>\n",
       "      <td>-0.150879</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.678842</td>\n",
       "      <td>0.036834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569902</th>\n",
       "      <td>-1.247781</td>\n",
       "      <td>-1.478646</td>\n",
       "      <td>1.264406</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>0.215390</td>\n",
       "      <td>-0.159233</td>\n",
       "      <td>-0.059426</td>\n",
       "      <td>-0.042416</td>\n",
       "      <td>-0.043150</td>\n",
       "      <td>-0.242519</td>\n",
       "      <td>-0.386797</td>\n",
       "      <td>-0.291047</td>\n",
       "      <td>-0.020665</td>\n",
       "      <td>-0.172150</td>\n",
       "      <td>0.014284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569903</th>\n",
       "      <td>-0.841816</td>\n",
       "      <td>2.321149</td>\n",
       "      <td>-0.540101</td>\n",
       "      <td>-0.057954</td>\n",
       "      <td>-0.551259</td>\n",
       "      <td>0.107866</td>\n",
       "      <td>-0.061544</td>\n",
       "      <td>-0.081089</td>\n",
       "      <td>-0.057524</td>\n",
       "      <td>-0.259889</td>\n",
       "      <td>-0.643144</td>\n",
       "      <td>-0.258358</td>\n",
       "      <td>-0.021054</td>\n",
       "      <td>-0.265889</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569904</th>\n",
       "      <td>-1.212118</td>\n",
       "      <td>-1.348980</td>\n",
       "      <td>1.454567</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.600753</td>\n",
       "      <td>0.317209</td>\n",
       "      <td>-0.123615</td>\n",
       "      <td>-0.013282</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>-0.074642</td>\n",
       "      <td>-0.526200</td>\n",
       "      <td>0.211604</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.029616</td>\n",
       "      <td>0.014714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569905</th>\n",
       "      <td>-1.425906</td>\n",
       "      <td>-1.212851</td>\n",
       "      <td>1.309646</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>-0.004601</td>\n",
       "      <td>0.057258</td>\n",
       "      <td>-0.080021</td>\n",
       "      <td>-0.171818</td>\n",
       "      <td>-0.062403</td>\n",
       "      <td>-0.371161</td>\n",
       "      <td>0.715560</td>\n",
       "      <td>-0.061980</td>\n",
       "      <td>-0.008712</td>\n",
       "      <td>-0.073982</td>\n",
       "      <td>0.017838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1569906 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0       -0.723982  1.405642 -0.509183 -0.043489 -0.453891  0.017190 -0.045733   \n",
       "1        3.298144 -1.425085 -1.520087 -0.024649 -0.111459  0.825453 -0.316069   \n",
       "2       -0.785003  1.657681 -0.506929 -0.050599 -0.518908  0.079913 -0.053267   \n",
       "3       -0.802038  2.211745 -0.546086 -0.053113 -0.505308  0.063077 -0.056795   \n",
       "4        0.544230  2.852851  1.881443  0.427168  2.744118  5.206410 -0.559283   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1569901  0.343384 -0.512552 -0.687967  0.027071  0.303698 -0.851152  0.029134   \n",
       "1569902 -1.247781 -1.478646  1.264406  0.045499  0.215390 -0.159233 -0.059426   \n",
       "1569903 -0.841816  2.321149 -0.540101 -0.057954 -0.551259  0.107866 -0.061544   \n",
       "1569904 -1.212118 -1.348980  1.454567  0.096419  0.600753  0.317209 -0.123615   \n",
       "1569905 -1.425906 -1.212851  1.309646  0.020592 -0.004601  0.057258 -0.080021   \n",
       "\n",
       "              PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0        0.017456  0.019915  0.054392 -0.470635 -0.216196 -0.012250 -0.084373   \n",
       "1       -0.604433 -0.368913 -1.495695 -0.013148 -0.637633 -0.093273  0.901276   \n",
       "2       -0.029689 -0.000764 -0.039560 -0.289287 -0.179887 -0.011793 -0.104393   \n",
       "3       -0.051315 -0.048846 -0.215653 -0.828292 -0.296404 -0.022592 -0.271130   \n",
       "4        0.089575  0.541004  1.320186 -1.332039  4.079731  0.281829  1.283006   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1569901  0.315244  0.179364  0.798662 -0.150879  0.100868  0.025759  0.678842   \n",
       "1569902 -0.042416 -0.043150 -0.242519 -0.386797 -0.291047 -0.020665 -0.172150   \n",
       "1569903 -0.081089 -0.057524 -0.259889 -0.643144 -0.258358 -0.021054 -0.265889   \n",
       "1569904 -0.013282  0.024876 -0.074642 -0.526200  0.211604  0.017073  0.029616   \n",
       "1569905 -0.171818 -0.062403 -0.371161  0.715560 -0.061980 -0.008712 -0.073982   \n",
       "\n",
       "             PC15  \n",
       "0       -0.001162  \n",
       "1        0.023981  \n",
       "2       -0.001320  \n",
       "3       -0.000658  \n",
       "4       -0.026053  \n",
       "...           ...  \n",
       "1569901  0.036834  \n",
       "1569902  0.014284  \n",
       "1569903 -0.000574  \n",
       "1569904  0.014714  \n",
       "1569905  0.017838  \n",
       "\n",
       "[1569906 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.785003</td>\n",
       "      <td>1.657681</td>\n",
       "      <td>-0.506929</td>\n",
       "      <td>-0.050599</td>\n",
       "      <td>-0.518908</td>\n",
       "      <td>0.079913</td>\n",
       "      <td>-0.053267</td>\n",
       "      <td>-0.029689</td>\n",
       "      <td>-0.000764</td>\n",
       "      <td>-0.039560</td>\n",
       "      <td>-0.289287</td>\n",
       "      <td>-0.179887</td>\n",
       "      <td>-0.011793</td>\n",
       "      <td>-0.104393</td>\n",
       "      <td>-0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.802038</td>\n",
       "      <td>2.211745</td>\n",
       "      <td>-0.546086</td>\n",
       "      <td>-0.053113</td>\n",
       "      <td>-0.505308</td>\n",
       "      <td>0.063077</td>\n",
       "      <td>-0.056795</td>\n",
       "      <td>-0.051315</td>\n",
       "      <td>-0.048846</td>\n",
       "      <td>-0.215653</td>\n",
       "      <td>-0.828292</td>\n",
       "      <td>-0.296404</td>\n",
       "      <td>-0.022592</td>\n",
       "      <td>-0.271130</td>\n",
       "      <td>-0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.726011</td>\n",
       "      <td>1.198838</td>\n",
       "      <td>-0.491408</td>\n",
       "      <td>-0.043707</td>\n",
       "      <td>-0.470147</td>\n",
       "      <td>0.034556</td>\n",
       "      <td>-0.045349</td>\n",
       "      <td>0.019654</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.117939</td>\n",
       "      <td>-0.202292</td>\n",
       "      <td>-0.158644</td>\n",
       "      <td>-0.007374</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.001263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.772734</td>\n",
       "      <td>1.457680</td>\n",
       "      <td>-0.495099</td>\n",
       "      <td>-0.049000</td>\n",
       "      <td>-0.515639</td>\n",
       "      <td>0.077905</td>\n",
       "      <td>-0.051312</td>\n",
       "      <td>-0.017597</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>-0.143721</td>\n",
       "      <td>-0.148087</td>\n",
       "      <td>-0.008512</td>\n",
       "      <td>-0.050619</td>\n",
       "      <td>-0.001514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.547853</td>\n",
       "      <td>12.327210</td>\n",
       "      <td>23.732811</td>\n",
       "      <td>279.533905</td>\n",
       "      <td>-44.643639</td>\n",
       "      <td>-22.102262</td>\n",
       "      <td>-0.986734</td>\n",
       "      <td>0.446772</td>\n",
       "      <td>-3.180127</td>\n",
       "      <td>-13.028477</td>\n",
       "      <td>-4.967493</td>\n",
       "      <td>14.304883</td>\n",
       "      <td>0.846526</td>\n",
       "      <td>7.171854</td>\n",
       "      <td>83.742699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645663</th>\n",
       "      <td>-0.760433</td>\n",
       "      <td>1.548975</td>\n",
       "      <td>-0.507242</td>\n",
       "      <td>-0.047967</td>\n",
       "      <td>-0.493170</td>\n",
       "      <td>0.055173</td>\n",
       "      <td>-0.050211</td>\n",
       "      <td>-0.010580</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>-0.353491</td>\n",
       "      <td>-0.192613</td>\n",
       "      <td>-0.011813</td>\n",
       "      <td>-0.093923</td>\n",
       "      <td>-0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645664</th>\n",
       "      <td>3.475626</td>\n",
       "      <td>-1.446949</td>\n",
       "      <td>-1.398737</td>\n",
       "      <td>-0.003074</td>\n",
       "      <td>-0.173237</td>\n",
       "      <td>1.566787</td>\n",
       "      <td>-0.289812</td>\n",
       "      <td>-0.684234</td>\n",
       "      <td>-0.367597</td>\n",
       "      <td>-1.465663</td>\n",
       "      <td>-0.155180</td>\n",
       "      <td>-1.214700</td>\n",
       "      <td>-0.137583</td>\n",
       "      <td>2.014173</td>\n",
       "      <td>0.004905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645665</th>\n",
       "      <td>-1.247781</td>\n",
       "      <td>-1.478646</td>\n",
       "      <td>1.264406</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>0.215390</td>\n",
       "      <td>-0.159233</td>\n",
       "      <td>-0.059426</td>\n",
       "      <td>-0.042416</td>\n",
       "      <td>-0.043150</td>\n",
       "      <td>-0.242519</td>\n",
       "      <td>-0.386797</td>\n",
       "      <td>-0.291047</td>\n",
       "      <td>-0.020665</td>\n",
       "      <td>-0.172150</td>\n",
       "      <td>0.014284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645666</th>\n",
       "      <td>-0.841816</td>\n",
       "      <td>2.321149</td>\n",
       "      <td>-0.540101</td>\n",
       "      <td>-0.057954</td>\n",
       "      <td>-0.551259</td>\n",
       "      <td>0.107866</td>\n",
       "      <td>-0.061544</td>\n",
       "      <td>-0.081089</td>\n",
       "      <td>-0.057524</td>\n",
       "      <td>-0.259889</td>\n",
       "      <td>-0.643144</td>\n",
       "      <td>-0.258358</td>\n",
       "      <td>-0.021054</td>\n",
       "      <td>-0.265889</td>\n",
       "      <td>-0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645667</th>\n",
       "      <td>-1.212118</td>\n",
       "      <td>-1.348980</td>\n",
       "      <td>1.454567</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.600753</td>\n",
       "      <td>0.317209</td>\n",
       "      <td>-0.123615</td>\n",
       "      <td>-0.013282</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>-0.074642</td>\n",
       "      <td>-0.526200</td>\n",
       "      <td>0.211604</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.029616</td>\n",
       "      <td>0.014714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>645668 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PC1        PC2        PC3         PC4        PC5        PC6  \\\n",
       "0       -0.785003   1.657681  -0.506929   -0.050599  -0.518908   0.079913   \n",
       "1       -0.802038   2.211745  -0.546086   -0.053113  -0.505308   0.063077   \n",
       "2       -0.726011   1.198838  -0.491408   -0.043707  -0.470147   0.034556   \n",
       "3       -0.772734   1.457680  -0.495099   -0.049000  -0.515639   0.077905   \n",
       "4       23.547853  12.327210  23.732811  279.533905 -44.643639 -22.102262   \n",
       "...           ...        ...        ...         ...        ...        ...   \n",
       "645663  -0.760433   1.548975  -0.507242   -0.047967  -0.493170   0.055173   \n",
       "645664   3.475626  -1.446949  -1.398737   -0.003074  -0.173237   1.566787   \n",
       "645665  -1.247781  -1.478646   1.264406    0.045499   0.215390  -0.159233   \n",
       "645666  -0.841816   2.321149  -0.540101   -0.057954  -0.551259   0.107866   \n",
       "645667  -1.212118  -1.348980   1.454567    0.096419   0.600753   0.317209   \n",
       "\n",
       "             PC7       PC8       PC9       PC10      PC11       PC12  \\\n",
       "0      -0.053267 -0.029689 -0.000764  -0.039560 -0.289287  -0.179887   \n",
       "1      -0.056795 -0.051315 -0.048846  -0.215653 -0.828292  -0.296404   \n",
       "2      -0.045349  0.019654  0.038050   0.117939 -0.202292  -0.158644   \n",
       "3      -0.051312 -0.017597  0.016456   0.025595 -0.143721  -0.148087   \n",
       "4      -0.986734  0.446772 -3.180127 -13.028477 -4.967493  14.304883   \n",
       "...          ...       ...       ...        ...       ...        ...   \n",
       "645663 -0.050211 -0.010580  0.008195   0.000508 -0.353491  -0.192613   \n",
       "645664 -0.289812 -0.684234 -0.367597  -1.465663 -0.155180  -1.214700   \n",
       "645665 -0.059426 -0.042416 -0.043150  -0.242519 -0.386797  -0.291047   \n",
       "645666 -0.061544 -0.081089 -0.057524  -0.259889 -0.643144  -0.258358   \n",
       "645667 -0.123615 -0.013282  0.024876  -0.074642 -0.526200   0.211604   \n",
       "\n",
       "            PC13      PC14       PC15  \n",
       "0      -0.011793 -0.104393  -0.001320  \n",
       "1      -0.022592 -0.271130  -0.000658  \n",
       "2      -0.007374 -0.013347  -0.001263  \n",
       "3      -0.008512 -0.050619  -0.001514  \n",
       "4       0.846526  7.171854  83.742699  \n",
       "...          ...       ...        ...  \n",
       "645663 -0.011813 -0.093923  -0.001027  \n",
       "645664 -0.137583  2.014173   0.004905  \n",
       "645665 -0.020665 -0.172150   0.014284  \n",
       "645666 -0.021054 -0.265889  -0.000574  \n",
       "645667  0.017073  0.029616   0.014714  \n",
       "\n",
       "[645668 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 15\n",
    "name_cols = [f'PC{i}' for i in range(1, n_components + 1)]\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(df_train)\n",
    "reduced_train = pca.transform(df_train)\n",
    "reduced_test = pca.transform(df_test)\n",
    "reduced_train = pd.DataFrame(reduced_train, columns=name_cols)\n",
    "reduced_test = pd.DataFrame(reduced_test, columns=name_cols)\n",
    "display(reduced_train)\n",
    "display(reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = reduced_train, target_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = reduced_test, target_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, input_dim, output_dim):\n",
    "    gate_hidden_units_options = {\n",
    "        \"16\": [16], \n",
    "        \"32\": [32], \n",
    "        \"64\": [64], \n",
    "        \"32_16\": [32, 16]\n",
    "    }\n",
    "    \n",
    "    chosen_gate_hidden_units_str = trial.suggest_categorical('gate_hidden_units', list(gate_hidden_units_options.keys()))\n",
    "    chosen_gate_hidden_units = gate_hidden_units_options[chosen_gate_hidden_units_str]\n",
    "\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = MixtureOfExperts(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        num_experts=output_dim,  # Number of experts equals the number of classes\n",
    "        expert_hidden_units=[32, 64, 32],\n",
    "        gate_hidden_units=chosen_gate_hidden_units,\n",
    "        num_active_experts=3,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    \n",
    "    # Initialize the expert usage logger\n",
    "    expert_usage_logger = ExpertUsageLogger(model)\n",
    "\n",
    "    # Initialize the PyTorch Lightning trainer\n",
    "    logger = TensorBoardLogger(\"logs\", name=\"MoE_experimental\")\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_f2', mode='max') \n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=300,\n",
    "        logger=logger,\n",
    "        callbacks=[lr_monitor, checkpoint_callback, expert_usage_logger],\n",
    "        accelerator='gpu',\n",
    "    )\n",
    "    \n",
    "    # Create PyTorch DataLoaders\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_train.values, device='cuda'), torch.tensor(y_train, device='cuda')), batch_size=8192, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(torch.tensor(X_val.values, device='cuda'), torch.tensor(y_val, device='cuda')), batch_size=8192)\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_f2 = trainer.callback_metrics[\"val_f2\"].item()\n",
    "\n",
    "    return val_f2\n",
    "\n",
    "# Run the Optuna optimization\n",
    "def tune_model(X_train, y_train, X_val, y_val, input_dim, output_dim, n_trials=20):\n",
    "    gate_hidden_units_options = {\n",
    "        \"16\": [16], \n",
    "        \"32\": [32], \n",
    "        \"64\": [64], \n",
    "        \"32_16\": [32, 16]\n",
    "    }\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, input_dim, output_dim), \n",
    "                   n_trials=n_trials)\n",
    "    \n",
    "    print(f\"Best Hyperparameters: {study.best_params}\")\n",
    "    \n",
    "    # Optionally, retrain the model with the best hyperparameters and return it\n",
    "    best_params = study.best_params\n",
    "    best_gate_hidden_units = gate_hidden_units_options[best_params['gate_hidden_units']]\n",
    "    \n",
    "    best_model = MixtureOfExperts(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        num_experts=output_dim, \n",
    "        expert_hidden_units=[32, 64, 32],\n",
    "        gate_hidden_units=best_gate_hidden_units,\n",
    "        num_active_experts=3,\n",
    "        dropout_rate=best_params['dropout_rate']\n",
    "    )\n",
    "    \n",
    "    # Initialize the expert usage logger\n",
    "    expert_usage_logger = ExpertUsageLogger(best_model)\n",
    "\n",
    "    # Train the model with the best hyperparameters\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        callbacks=[expert_usage_logger],\n",
    "        accelerator='gpu'\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=4096, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=4096)\n",
    "    \n",
    "    trainer.fit(best_model, train_loader, val_loader)\n",
    "    \n",
    "    expert_usage_logger.plot_expert_usage()\n",
    "    \n",
    "    return best_model, study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-03 14:36:39,738] A new study created in memory with name: no-name-cea7c07c-b864-4065-8ea8-075c74559952\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2024-09-03 14:36:40.377971: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 14:36:40.398217: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 14:36:40.401223: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | experts   | ModuleList       | 4.7 K  | train\n",
      "1 | gate      | GateModel        | 1.1 K  | train\n",
      "2 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "5.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  81%|████████  | 155/192 [00:12<00:02, 12.70it/s, v_num=8]        "
     ]
    }
   ],
   "source": [
    "tune_model(X, y, X_test, y_test, X.shape[1], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
